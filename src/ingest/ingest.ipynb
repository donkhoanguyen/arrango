{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9473,
     "status": "ok",
     "timestamp": 1741012485785,
     "user": {
      "displayName": "Vuong Ho",
      "userId": "00142954554496901229"
     },
     "user_tz": 300
    },
    "id": "gbR1cwhT94xR",
    "outputId": "ba026262-47b9-4861-b2ea-041a47672287"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install python packages\n",
    "!pip install streamlit pyvis networkx -q\n",
    "\n",
    "# For reading pdf\n",
    "!pip install pymupdf -q\n",
    "\n",
    "# For langchain\n",
    "!pip install langchain langchain-openai -q\n",
    "\n",
    "# For graph visualization\n",
    "!pip install st-link-analysis\n",
    "\n",
    "# For speaking with ArangoDB\n",
    "!pip install python-arango nx-arangodb\n",
    "\n",
    "# Install localtunnel to access streamlit app\n",
    "!npm install localtunnel -y -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FthMAB4O94xU",
    "outputId": "5f032c43-93cf-4622-9c27-1a96a4a49ff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frontend file created successfully.\n",
      "The password to the demo website is '35.232.213.169'\n",
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.232.213.169:8501\u001b[0m\n",
      "\u001b[0m\n",
      "your url is: https://arango-hack.loca.lt\n",
      "/content/app.py:76: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(return_messages=True)\n",
      "/content/app.py:79: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "# Prepare app.py for opening streamlit\n",
    "\n",
    "code = \"\"\"\n",
    "import streamlit as st\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import fitz  # PyMuPDF\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# --- Initialize session state ---\n",
    "if \"graph\" not in st.session_state:\n",
    "    st.session_state.graph = nx.Graph()\n",
    "\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state.chat_history = []\n",
    "\n",
    "if \"documents_text\" not in st.session_state:\n",
    "    st.session_state.documents_text = []\n",
    "\n",
    "# --- Page Layout ---\n",
    "st.set_page_config(layout=\"wide\")  # Set to full-screen mode\n",
    "\n",
    "# Sidebar for Upload and API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = st.sidebar.text_input(\"OpenAI API Key\", type=\"password\")\n",
    "\n",
    "st.sidebar.title(\"Upload Documents\")\n",
    "uploaded_files = st.sidebar.file_uploader(\"Upload project-related documents (PDF only)\",\n",
    "                                          accept_multiple_files=True, type=[\"pdf\"])\n",
    "\n",
    "# --- Function to extract text from PDFs ---\n",
    "def extract_text_from_pdfs(files):\n",
    "    extracted_texts = []\n",
    "    for file in files:\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_pdf:\n",
    "            temp_pdf.write(file.read())\n",
    "            temp_pdf_path = temp_pdf.name\n",
    "\n",
    "        doc = fitz.open(temp_pdf_path)\n",
    "        text = \"\\\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "        extracted_texts.append(text)\n",
    "\n",
    "        os.remove(temp_pdf_path)  # Cleanup temporary file\n",
    "    return extracted_texts\n",
    "\n",
    "# Process uploaded PDFs when \"Generate Graph\" is clicked\n",
    "if st.sidebar.button(\"Generate Graph\"):\n",
    "    if uploaded_files:\n",
    "        st.session_state.documents_text = extract_text_from_pdfs(uploaded_files)\n",
    "        st.session_state.graph = nx.erdos_renyi_graph(10, 0.3)  # Placeholder for processing logic\n",
    "        st.sidebar.success(\"Graph generated successfully!\")\n",
    "    else:\n",
    "        st.sidebar.warning(\"Please upload at least one PDF file.\")\n",
    "\n",
    "# Create two columns: Left (1/3) for chatbot, Right (2/3) for graph\n",
    "left_col, right_col = st.columns([1, 2])\n",
    "\n",
    "# Methods for Chatbot UI\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "st.session_state[\"openai_model\"] = \"gpt-4o\"\n",
    "\n",
    "# Initialize ChatOpenAI with a default API key (or None)\n",
    "llm = ChatOpenAI(\n",
    "    model=st.session_state[\"openai_model\"],\n",
    "    streaming=True,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Initialize ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# Initialize ConversationChain\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# --- Left Panel (Chatbot UI) ---\n",
    "with left_col:\n",
    "    st.title(\"Interactive GraphRAG ETL\")\n",
    "    st.write(\"Upload your project-related documents for processing and modify them here.\")\n",
    "\n",
    "    if not os.environ[\"OPENAI_API_KEY\"] .startswith(\"sk-\"):\n",
    "        st.warning(\"Please enter your OpenAI API key!\", icon=\"⚠\")\n",
    "\n",
    "\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "\n",
    "    if prompt := st.chat_input(\"Enter your query here\"):\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        response = conversation.predict(input=prompt)\n",
    "\n",
    "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "        # Update the conversation memory\n",
    "        conversation.memory.chat_memory.messages = [\n",
    "            SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "            *[HumanMessage(content=m[\"content\"]) if m[\"role\"] == \"user\" else AIMessage(content=m[\"content\"])\n",
    "              for m in st.session_state.messages]\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "# --- Right Panel (Graph Visualization) ---\n",
    "with right_col:\n",
    "    # Save Pyvis network to an HTML file\n",
    "    def draw_graph(graph):\n",
    "        net = Network(height=\"700px\", width=\"100%\", notebook=False, bgcolor=\"#ffffff\", font_color=\"black\")\n",
    "        net.from_nx(graph)\n",
    "\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".html\") as tmp_file:\n",
    "            net.save_graph(tmp_file.name)\n",
    "            return tmp_file.name\n",
    "\n",
    "    if st.session_state.graph.nodes:\n",
    "        graph_html = draw_graph(st.session_state.graph)\n",
    "        with open(graph_html, \"r\", encoding=\"utf-8\") as file:\n",
    "            st.components.v1.html(file.read(), height=700, scrolling=False)\n",
    "        os.unlink(graph_html)  # Cleanup\n",
    "    else:\n",
    "        st.write(\"No graph to display. Upload files and generate a graph.\")\n",
    "\n",
    "# Debug: Show extracted text from PDFs\n",
    "if st.sidebar.checkbox(\"Show Extracted Text\"):\n",
    "    for idx, text in enumerate(st.session_state.documents_text):\n",
    "        st.sidebar.write(f\"### Document {idx + 1} Content:\")\n",
    "        st.sidebar.text_area(\"\", text, height=200, disabled=True)\n",
    "\"\"\"\n",
    "\n",
    "with open(\"app.py\", \"w\") as f:\n",
    "    f.write(code)\n",
    "\n",
    "print(\"Frontend file created successfully.\")\n",
    "\n",
    "# Run the app to expose app to outside world\n",
    "!echo \"The password to the demo website is '$(wget -q -O - ipv4.icanhazip.com)'\"\n",
    "!streamlit run app.py & npx localtunnel --port 8501 --subdomain arango-hack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXxYF6RXAqms"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

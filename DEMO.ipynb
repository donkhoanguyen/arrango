{"cells":[{"cell_type":"markdown","source":["# **Confluence Copilot** Demo Notebook\n","\n","Disclaimer: Since we built our application with Streamlit, we have to develop with Python `.py` files instead of in-notebook. This results in a much better UI/UX, as you will see later, but setting these thing up to be ran in a Jupyter Notebook might take some time. However, we believe the experience will be worth your while, so stick around :)\n","\n","## Installation\n","First, we have to clone our git repository and change directory to `arrango/src/ingest`.\n","\n","NOTE: MAKE SURE TO RUN THIS CODE CELL BELOW ONLY ONCE!"],"metadata":{"id":"j_a44B7MvasL"}},{"cell_type":"code","execution_count":1,"metadata":{"vscode":{"languageId":"plaintext"},"id":"OOnkeuGyvPmC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741627443166,"user_tz":240,"elapsed":1635,"user":{"displayName":"Vuong Ho","userId":"00142954554496901229"}},"outputId":"637890c1-be37-4ca0-fa3a-dc6e249458e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'arrango'...\n","remote: Enumerating objects: 999, done.\u001b[K\n","remote: Counting objects: 100% (363/363), done.\u001b[K\n","remote: Compressing objects: 100% (180/180), done.\u001b[K\n","remote: Total 999 (delta 244), reused 289 (delta 182), pack-reused 636 (from 1)\u001b[K\n","Receiving objects: 100% (999/999), 1.57 MiB | 4.16 MiB/s, done.\n","Resolving deltas: 100% (537/537), done.\n","/content/arrango/src/ingest\n","This should say context/arrango/src/ingest\n","/content/arrango/src/ingest\n"]}],"source":["# Clone repository\n","!git clone https://github.com/donkhoanguyen/arrango\n","\n","# Change directory\n","%cd arrango/src/ingest\n","\n","# Confirming directory\n","!echo \"This should say context/arrango/src/ingest\"\n","!pwd"]},{"cell_type":"markdown","source":["Next, we install required packages for pip.\n","\n","## NOTE: It may report some errors about compatibility below, but it is a non-problem and you should continue to run this script to demo."],"metadata":{"id":"38paI5cQxGhT"}},{"cell_type":"code","source":["!git pull\n","!pip install -r requirements.txt -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AD8HudJTwE4j","outputId":"a956b0b7-18f3-4f2c-ef5f-d9d7cd0a3b8a","executionInfo":{"status":"ok","timestamp":1741627499468,"user_tz":240,"elapsed":56301,"user":{"displayName":"Vuong Ho","userId":"00142954554496901229"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Already up to date.\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m600.2/600.2 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.6/134.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.2/473.2 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m874.5/874.5 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.6/427.6 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires ipykernel==6.17.1, but you have ipykernel 6.29.5 which is incompatible.\n","google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 9.0.1 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n","jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.8.0 which is incompatible.\n","moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.2.1 which is incompatible.\n","gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\n","notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\n","notebook 6.5.5 requires pyzmq<25,>=17, but you have pyzmq 26.2.1 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"markdown","source":["We know this is a bad idea, but we haven't written a script to upload our graph data at will yet, so you can use our ArangoDB credentials for now. This `demo` user only have read access to our database.\n","\n","\n","Now, make sure to input your own OPENAI_API_KEY and then run the scripts below to load the `secrets.toml` secrets file required by Streamlit."],"metadata":{"id":"nCezqwpSzx_b"}},{"cell_type":"code","source":["from getpass import getpass\n","OPENAI_API_KEY = getpass(\"Enter your OPENAI_API_KEY: \")\n","print(\"Secret stored securely!\")\n","\n","secrets = f\"\"\"\n","OPENAI_API_KEY = \\\"{OPENAI_API_KEY}\\\"\n","\n","LANGSMITH_TRACING=\\\"false\\\"\n","LANGSMITH_ENDPOINT=\\\"xxxxxxxxxxxx\\\"\n","LANGSMITH_API_KEY=\\\"xxxxxxxxxxxx\\\"\n","LANGSMITH_PROJECT=\\\"xxxxxxxxxxxx\\\"\n","\n","DATABASE_HOST = \\\"https://b61c3b83bfe6.arangodb.cloud:8529\\\"\n","DATABASE_USERNAME = \\\"demo\\\"\n","DATABASE_PASSWORD = \\\"thisisademo\\\"\n","DATABASE_NAME = \\\"DAC_devops_log\\\"\n","\"\"\"\n","with open(\".streamlit/secrets.toml\", \"w\") as file:\n","    file.write(secrets)"],"metadata":{"id":"9S5BNa8ezL5l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741627668791,"user_tz":240,"elapsed":14294,"user":{"displayName":"Vuong Ho","userId":"00142954554496901229"}},"outputId":"b4b88169-b921-49be-be67-cce4345bd71d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter your OPENAI_API_KEY: ··········\n","Secret stored securely!\n"]}]},{"cell_type":"markdown","source":["We will be hosting our website with `localtunnel`, which requires a password to access. You can get the password below."],"metadata":{"id":"sXdTWpCbC5GQ"}},{"cell_type":"code","source":["!npm install localtunnel -y --silent\n","!echo \"Input password for website below is '$(wget -q -O - ipv4.icanhazip.com)'\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4DSEmRIysfI","outputId":"c4118f87-b349-4c02-812d-b4b62f625775","executionInfo":{"status":"ok","timestamp":1741627719247,"user_tz":240,"elapsed":1015,"user":{"displayName":"Vuong Ho","userId":"00142954554496901229"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Input password for website below is '34.125.158.137'\n"]}]},{"cell_type":"markdown","source":["Now, run the localtunnel to get an URL to access outside. It should be `https://confluence.copilot.loca.lt`"],"metadata":{"id":"VK1213YVDJAc"}},{"cell_type":"code","source":["!streamlit run app.py & npx localtunnel --port 8501 --subdomain confluence-copilot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"naAC1Kw3x_YO","outputId":"38513e4b-3591-4eea-a7d8-3293a4679e4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\u001b[0m\n","\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://confluence-copilot.loca.lt\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.158.137:8501\u001b[0m\n","\u001b[0m\n","[17:29:08 +0000] [INFO]: NetworkX-cuGraph is available.\n","[17:29:10 +0000] [INFO]: Graph 'bi_team_task_assignment' exists.\n","[17:29:10 +0000] [INFO]: Default node type set to 'employee'\n","[17:29:11 +0000] [INFO]: Graph 'employee_interaction' exists.\n","[17:29:11 +0000] [INFO]: Default node type set to 'employee'\n","Graph named 'employee_interaction' with 36 nodes and 403 edges\n","[17:29:11 +0000] [WARNING]: Note that copying a graph loses the connection to the database\n","[17:29:11 +0000] [WARNING]: Note that setting the graph name does not create the graph in the database\n","[17:29:11 +0000] [INFO]: Graph 'bi_tasks_dependence_graph' exists.\n","[17:29:11 +0000] [INFO]: Default node type set to 'bi_tasks'\n","Failed to read ArangoDB environment information: ArangoDB error: code 11, message: not authorized to execute this request, HTTP status code: 401 Unauthorized. This can happen if the current user is not allowed to access the '/_admin/support-info' endpoint. Assuming ArangoDB instance version is at least '3.12'. We will use the aql load strategy as the loading strategy. While this works, this will be slower then using the dump endpoint instead. Failed to read ArangoDB environment information: ArangoDB error: code 11, message: not authorized to execute this request, HTTP status code: 401 Unauthorized. This can happen if the current user is not allowed to access the '/_admin/support-info' endpoint. Assuming ArangoDB instance version is at least '3.12'. We will use the aql load strategy as the loading strategy. While this works, this will be slower then using the dump endpoint instead. Failed to read ArangoDB environment information: /usr/local/lib/python3.11/dist-packages/st_link_analysis/component/styles.py:119: LinkAnalysisDeprecationWarning: Paramter `labeled` is deprecated and will be removed in a future release. Please use the `caption` parameter instead.\n","  warnings.warn(\n","content=\"You are a helpful chatbot in a Project Dashboard of a human company. The user's context is this 'The user might want to know more about things related to this following graph NetworkX DiGraph with name 'bi_tasks_dependence_graph', schema: {'nodes': ['task'], 'edges': ['depends on'], 'tasks_col': 'bi_tasks'}, and overall description: This is the graph of task dependence for the project StreamSync Pipeline. Note that this chatbot is not for visualizing graph, so if the user ask about it, kindly redirects them to use the '✨ Magic View' option in the 'Choose how you want to view' dropdown'. First, warmly welcome the user and explain quickly about what you can do, including explaining 2 or 3 type and example questions you are equpiped best to answer with the given context. Do it in under 100 words, and make sure the questions are in markdown list.\" additional_kwargs={} response_metadata={}\n","system\n","content=\"You are a helpful AI assistant that answers user queries by interacting with our graph databases, performing network computations, and extracting insights or executing tasks.\\n\\n### Workflow:\\n1. Identify if the query requires a graph.\\n2. Select the appropriate graph (Current graph: 'None') using the available tools.\\n3. Perform necessary calculations or analyses using the provided tools.\\n4. Generate a natural language response or execute the requested task based on the computed data.\\n\\n### Context:\\nYou also serve as a base chatbot for a more in-context assistant. Tailor your responses using the provided original context:\\n\\n**User Query:** 'You are a helpful chatbot in a Project Dashboard of a human company. The user's context is this 'The user might want to know more about things related to this following graph NetworkX DiGraph with name 'bi_tasks_dependence_graph', schema: {'nodes': ['task'], 'edges': ['depends on'], 'tasks_col': 'bi_tasks'}, and overall description: This is the graph of task dependence for the project StreamSync Pipeline. Note that this chatbot is not for visualizing graph, so if the user ask about it, kindly redirects them to use the '✨ Magic View' option in the 'Choose how you want to view' dropdown'. First, warmly welcome the user and explain quickly about what you can do, including explaining 2 or 3 type and example questions you are equpiped best to answer with the given context. Do it in under 100 words, and make sure the questions are in markdown list.'  \\n**Original Context:** 'The user might want to know more about things related to this following graph NetworkX DiGraph with name 'bi_tasks_dependence_graph', schema: {'nodes': ['task'], 'edges': ['depends on'], 'tasks_col': 'bi_tasks'}, and overall description: This is the graph of task dependence for the project StreamSync Pipeline. Note that this chatbot is not for visualizing graph, so if the user ask about it, kindly redirects them to use the '✨ Magic View' option in the 'Choose how you want to view' dropdown'  \\n\\n### Instructions:\\n- Always consider the original user query.\\n- If multiple tools are needed, combine them effectively to derive the final result.  \" additional_kwargs={} response_metadata={}\n","/usr/local/lib/python3.11/dist-packages/st_link_analysis/component/styles.py:119: LinkAnalysisDeprecationWarning: Paramter `labeled` is deprecated and will be removed in a future release. Please use the `caption` parameter instead.\n","  warnings.warn(\n","content=\"You are a helpful chatbot in a Project Dashboard of a human company. The user's context is this 'The user might want to know more about things related to this following graph NetworkX DiGraph with name 'bi_tasks_dependence_graph', schema: {'nodes': ['task'], 'edges': ['depends on'], 'tasks_col': 'bi_tasks'}, and overall description: This is the graph of task dependence for the project StreamSync Pipeline. Note that this chatbot is not for visualizing graph, so if the user ask about it, kindly redirects them to use the '✨ Magic View' option in the 'Choose how you want to view' dropdown'. First, warmly welcome the user and explain quickly about what you can do, including explaining 2 or 3 type and example questions you are equpiped best to answer with the given context. Do it in under 100 words, and make sure the questions are in markdown list.\" additional_kwargs={} response_metadata={} id='366b9bc8-fa49-4608-81c9-328f52b0cb13'\n","system\n","content=\"Hello and welcome to the Project Dashboard! I'm here to assist you with insights about task dependencies in the StreamSync Pipeline project. I can help answer questions like:\\n\\n- **What are the next tasks I should focus on?**\\n- **Which tasks have dependencies that might delay the project?**\\n- **How can I optimize the order of tasks using the Critical Path Method?**\\n\\nFeel free to ask any questions related to task management, and I'll do my best to assist you!\" additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8'} id='run-632e4cae-2000-409f-85ec-aafe977a845c'\n","ai\n","content=\"You are a helpful chatbot in a Project Dashboard of a human company. The user's context is this 'You are answering question about this employee, here is their details {'EmpID': '3', 'FirstName': 'Timothy', 'LastName': 'Johnson', 'Email': 'timothy.johnson@company.com', 'Role': 'Business Intelligence Lead', 'Department': 'Data', 'Team': 'Business Intelligence', 'Seniority': 'Lead', 'HireDate': '2018-01-23', 'Salary': 72433, 'ManagerID': '2.0'}'. First, warmly welcome the user and explain quickly about what you can do, including explaining 2 or 3 type and example questions you are equpiped best to answer with the given context. Do it in under 100 words, and make sure the questions are in markdown list.\" additional_kwargs={} response_metadata={}\n","system\n","content=\"You are a helpful AI assistant that answers user queries by interacting with our graph databases, performing network computations, and extracting insights or executing tasks.\\n\\n### Workflow:\\n1. Identify if the query requires a graph.\\n2. Select the appropriate graph (Current graph: 'None') using the available tools.\\n3. Perform necessary calculations or analyses using the provided tools.\\n4. Generate a natural language response or execute the requested task based on the computed data.\\n\\n### Context:\\nYou also serve as a base chatbot for a more in-context assistant. Tailor your responses using the provided original context:\\n\\n**User Query:** 'You are a helpful chatbot in a Project Dashboard of a human company. The user's context is this 'You are answering question about this employee, here is their details {'EmpID': '3', 'FirstName': 'Timothy', 'LastName': 'Johnson', 'Email': 'timothy.johnson@company.com', 'Role': 'Business Intelligence Lead', 'Department': 'Data', 'Team': 'Business Intelligence', 'Seniority': 'Lead', 'HireDate': '2018-01-23', 'Salary': 72433, 'ManagerID': '2.0'}'. First, warmly welcome the user and explain quickly about what you can do, including explaining 2 or 3 type and example questions you are equpiped best to answer with the given context. Do it in under 100 words, and make sure the questions are in markdown list.'  \\n**Original Context:** 'You are answering question about this employee, here is their details {'EmpID': '3', 'FirstName': 'Timothy', 'LastName': 'Johnson', 'Email': 'timothy.johnson@company.com', 'Role': 'Business Intelligence Lead', 'Department': 'Data', 'Team': 'Business Intelligence', 'Seniority': 'Lead', 'HireDate': '2018-01-23', 'Salary': 72433, 'ManagerID': '2.0'}'  \\n\\n### Instructions:\\n- Always consider the original user query.\\n- If multiple tools are needed, combine them effectively to derive the final result.  \" additional_kwargs={} response_metadata={}\n","content=\"You are a helpful chatbot in a Project Dashboard of a human company. The user's context is this 'You are answering question about this employee, here is their details {'EmpID': '3', 'FirstName': 'Timothy', 'LastName': 'Johnson', 'Email': 'timothy.johnson@company.com', 'Role': 'Business Intelligence Lead', 'Department': 'Data', 'Team': 'Business Intelligence', 'Seniority': 'Lead', 'HireDate': '2018-01-23', 'Salary': 72433, 'ManagerID': '2.0'}'. First, warmly welcome the user and explain quickly about what you can do, including explaining 2 or 3 type and example questions you are equpiped best to answer with the given context. Do it in under 100 words, and make sure the questions are in markdown list.\" additional_kwargs={} response_metadata={} id='8f7ef5ad-a2fa-47c8-a012-2037b500be38'\n","system\n","content='Hello! It\\'s great to have you here. I\\'m here to assist with insights and tasks related to your project dashboard. Here\\'s how I can help:\\n\\n- **Team Dynamics**: \"Who in the Business Intelligence team could be on the managerial track?\"\\n- **Task Prioritization**: \"What are the next critical tasks for the Data department?\"\\n- **Employee Insights**: \"What is Timothy Johnson\\'s tendency towards management or technical roles?\"\\n\\nFeel free to ask anything else you need!' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8'} id='run-b3e52692-613b-44ff-bc51-198ae7804fa4'\n","ai\n","content='conduct hits' additional_kwargs={} response_metadata={}\n","human\n","content=\"You are a helpful AI assistant that answers user queries by interacting with our graph databases, performing network computations, and extracting insights or executing tasks.\\n\\n### Workflow:\\n1. Identify if the query requires a graph.\\n2. Select the appropriate graph (Current graph: 'None') using the available tools.\\n3. Perform necessary calculations or analyses using the provided tools.\\n4. Generate a natural language response or execute the requested task based on the computed data.\\n\\n### Context:\\nYou also serve as a base chatbot for a more in-context assistant. Tailor your responses using the provided original context:\\n\\n**User Query:** 'conduct hits'  \\n**Original Context:** 'You are answering question about this employee, here is their details {'EmpID': '3', 'FirstName': 'Timothy', 'LastName': 'Johnson', 'Email': 'timothy.johnson@company.com', 'Role': 'Business Intelligence Lead', 'Department': 'Data', 'Team': 'Business Intelligence', 'Seniority': 'Lead', 'HireDate': '2018-01-23', 'Salary': 72433, 'ManagerID': '2.0'}'  \\n\\n### Instructions:\\n- Always consider the original user query.\\n- If multiple tools are needed, combine them effectively to derive the final result.  \" additional_kwargs={} response_metadata={}\n","Current state graph name in tool : None\n","calling tool choose_graph\n","args: {'query': 'conduct hits', 'context': 'Graph containing employee details such as EmpID, FirstName, LastName, Role, Department, Team, Seniority, HireDate, Salary, and ManagerID. Graph may also include relationships or interactions between employees.', 'other_instruction': 'Determine which employees are suitable for managerial or technical tracks using the HITS algorithm.'}\n","content=\"You are a helpful AI assistant that answers user queries by interacting with our graph databases, performing network computations, and extracting insights or executing tasks.\\n\\n### Workflow:\\n1. Identify if the query requires a graph.\\n2. Select the appropriate graph (Current graph: 'NetworkX DiGraph with name 'Business Intelligence_employee_interaction', schema: {'nodes': ['employee'], 'edges': ['interacts with']}, and overall description: The graph of extended interaction and help between employees of the company') using the available tools.\\n3. Perform necessary calculations or analyses using the provided tools.\\n4. Generate a natural language response or execute the requested task based on the computed data.\\n\\n### Context:\\nYou also serve as a base chatbot for a more in-context assistant. Tailor your responses using the provided original context:\\n\\n**User Query:** 'conduct hits'  \\n**Original Context:** 'You are answering question about this employee, here is their details {'EmpID': '3', 'FirstName': 'Timothy', 'LastName': 'Johnson', 'Email': 'timothy.johnson@company.com', 'Role': 'Business Intelligence Lead', 'Department': 'Data', 'Team': 'Business Intelligence', 'Seniority': 'Lead', 'HireDate': '2018-01-23', 'Salary': 72433, 'ManagerID': '2.0'}'  \\n\\n### Instructions:\\n- Always consider the original user query.\\n- If multiple tools are needed, combine them effectively to derive the final result.  \" additional_kwargs={} response_metadata={}\n","Current state graph name in tool : Business Intelligence_employee_interaction\n","calling tool create_hits_table\n","args: {'G_adb': 'Business Intelligence_employee_interaction'}\n","[17:29:32 +0000] [INFO]: Graph 'emp_interaction1' exists.\n","[17:29:32 +0000] [INFO]: Default node type set to 'emp_interaction1_node'\n","ArangoDB error: code 11, message: not authorized to execute this request, HTTP status code: 401 Unauthorized. This can happen if the current user is not allowed to access the '/_admin/support-info' endpoint. Assuming ArangoDB instance version is at least '3.12'. We will use the aql load strategy as the loading strategy. While this works, this will be slower then using the dump endpoint instead. Failed to read ArangoDB environment information: ArangoDB error: code 11, message: not authorized to execute this request, HTTP status code: 401 Unauthorized. This can happen if the current user is not allowed to access the '/_admin/support-info' endpoint. Assuming ArangoDB instance version is at least '3.12'. We will use the aql load strategy as the loading strategy. While this works, this will be slower then using the dump endpoint instead. Failed to read ArangoDB environment information: ArangoDB error: code 11, message: not authorized to execute this request, HTTP status code: 401 Unauthorized[17:29:32 +0000] [INFO]: Graph 'emp_interaction1' load took 0.11213994026184082s\n","[17:29:34 +0000] [INFO]: NXCG Graph construction took 2.0955615043640137s\n","2025-03-10 17:29:34.717 Uncaught app execution\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/fragment.py\", line 244, in wrapped_fragment\n","    result = non_optional_func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/streamlit/elements/dialog_decorator.py\", line 99, in dialog_content\n","    _ = non_optional_func(*args, **kwargs)\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/content/arrango/src/ingest/component.py\", line 94, in ask\n","    chatbot.render()\n","  File \"/content/arrango/src/ingest/chatbot.py\", line 109, in render\n","    st.write_stream(self.process_stream(stream))\n","  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/metrics_util.py\", line 410, in wrapped_func\n","    result = non_optional_func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/streamlit/elements/write.py\", line 189, in write_stream\n","    for chunk in stream:  # type: ignore\n","  File \"/content/arrango/src/ingest/chatbot.py\", line 64, in process_stream\n","    for type, chunk in stream:\n","  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\", line 2024, in stream\n","    for _ in runner.tick(\n","  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\", line 302, in tick\n","    _panic_or_proceed(\n","  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\", line 619, in _panic_or_proceed\n","    raise exc\n","  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/executor.py\", line 83, in done\n","    task.result()\n","  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n","    return self.__get_result()\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n","    raise self._exception\n","  File \"/usr/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n","    result = self.fn(*self.args, **self.kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n","    return task.proc.invoke(task.input, config)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\", line 546, in invoke\n","    input = step.invoke(input, config, **kwargs)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\", line 310, in invoke\n","    ret = context.run(self.func, *args, **kwargs)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/content/arrango/src/ingest/agent/__init__.py\", line 192, in tool_node\n","    tool_result = tools_by_name[tool_call[\"name\"]].invoke({\"G_adb\": graph_wrapper.graph})\n","                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 509, in invoke\n","    return self.run(tool_input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 763, in run\n","    raise error_to_raise\n","  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 732, in run\n","    response = context.run(self._run, *tool_args, **tool_kwargs)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/structured.py\", line 89, in _run\n","    return self.func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/content/arrango/src/ingest/agent/hits.py\", line 78, in create_hits_table\n","    hubs, authorities = nx.hits(G_adb, iter=10000, tol=1e-2)\n","                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/networkx/utils/decorators.py\", line 789, in func\n","    return argmap._lazy_compile(__wrapper)(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<class 'networkx.utils.decorators.argmap'> compilation 4\", line 3, in argmap_hits_1\n","    import gzip\n","            ^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/networkx/utils/backends.py\", line 1336, in __call__\n","    return self._call_with_backend(backend_name, args, kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/networkx/utils/backends.py\", line 1848, in _call_with_backend\n","    return getattr(backend, self.name)(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nx_arangodb/interface.py\", line 79, in _auto_func\n","    return _run_with_backend(\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nx_arangodb/interface.py\", line 170, in _run_with_backend\n","    result = backend_func(*converted_args, **converted_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nx_cugraph/utils/decorators.py\", line 156, in __call__\n","    return self.__wrapped__(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","TypeError: hits() got an unexpected keyword argument 'iter'\n","During task with name 'tools' and id '68916471-0b41-dc2f-9112-516f199a9acf'\n"]}]},{"cell_type":"markdown","source":["# Time for some write up\n","\n","## Source code\n","The majority of the GraphRAG Agent work is in the `src/ingest/agent` directory of our here [GitHub repo](https://github.com/donkhoanguyen/arrango/tree/main/src/ingest/agent).\n","\n","In this directory, the `__init__.py` contains the starting point for our agent, where it gathers tools defined in other `.py` file within the `agent` directory. For details and prompts for each of the tools, make sure to read the docstring of individual tools in the directory as well as the [prompt](https://github.com/donkhoanguyen/arrango/tree/main/src/ingest/agent/prompt).\n","\n","\n","## Architecture\n"],"metadata":{"id":"B59vjGcfEm2q"}}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}